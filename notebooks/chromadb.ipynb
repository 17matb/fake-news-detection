{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "270901a5",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23a8d2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import re\n",
    "import pandas as pd\n",
    "from chromadb.utils import embedding_functions\n",
    "from html import unescape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d993290",
   "metadata": {},
   "source": [
    "### Chargement CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "728841ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_df = pd.read_csv('../data/Fake.csv')\n",
    "true_df = pd.read_csv('../data/True.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0add3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_df['label'] = 'fake'\n",
    "true_df['label'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0effbcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_fake_df = fake_df.copy()\n",
    "clean_true_df = true_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d992a1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_fake_df = clean_fake_df.drop_duplicates('text')\n",
    "clean_true_df = clean_true_df.drop_duplicates('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60dfdeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_if_brackets(text):\n",
    "    if text.strip().startswith('[') and text.strip().endswith(']'):\n",
    "        return ''\n",
    "    return text\n",
    "\n",
    "\n",
    "clean_fake_df['text'] = clean_fake_df['text'].apply(lambda x: remove_if_brackets(x))\n",
    "clean_fake_df['title'] = clean_fake_df['title'].apply(lambda x: remove_if_brackets(x))\n",
    "\n",
    "clean_true_df['text'] = clean_true_df['text'].apply(lambda x: remove_if_brackets(x))\n",
    "clean_true_df['title'] = clean_true_df['title'].apply(lambda x: remove_if_brackets(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b81848c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_spaces(text):\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "\n",
    "clean_fake_df['text'] = clean_fake_df['text'].apply(lambda x: normalize_spaces(x))\n",
    "clean_fake_df['title'] = clean_fake_df['title'].apply(lambda x: normalize_spaces(x))\n",
    "\n",
    "clean_true_df['text'] = clean_true_df['text'].apply(lambda x: normalize_spaces(x))\n",
    "clean_true_df['title'] = clean_true_df['title'].apply(lambda x: normalize_spaces(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f35f0274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(text):\n",
    "    return re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "\n",
    "\n",
    "clean_fake_df['text'] = clean_fake_df['text'].apply(\n",
    "    lambda x: remove_special_characters(x)\n",
    ")\n",
    "clean_fake_df['title'] = clean_fake_df['title'].apply(\n",
    "    lambda x: remove_special_characters(x)\n",
    ")\n",
    "\n",
    "clean_true_df['text'] = clean_true_df['text'].apply(\n",
    "    lambda x: remove_special_characters(x)\n",
    ")\n",
    "clean_true_df['title'] = clean_true_df['title'].apply(\n",
    "    lambda x: remove_special_characters(x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cf0f537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    return re.sub(r'http\\S+|www\\S+', '', text)\n",
    "\n",
    "\n",
    "clean_fake_df['text'] = clean_fake_df['text'].apply(lambda x: remove_urls(x))\n",
    "clean_fake_df['title'] = clean_fake_df['title'].apply(lambda x: remove_urls(x))\n",
    "\n",
    "clean_true_df['text'] = clean_true_df['text'].apply(lambda x: remove_urls(x))\n",
    "clean_true_df['title'] = clean_true_df['title'].apply(lambda x: remove_urls(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03caa462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    return re.sub(r'<.*?>', '', text)\n",
    "\n",
    "\n",
    "clean_fake_df['text'] = clean_fake_df['text'].apply(lambda x: remove_html_tags(x))\n",
    "clean_fake_df['title'] = clean_fake_df['title'].apply(lambda x: remove_html_tags(x))\n",
    "\n",
    "clean_true_df['text'] = clean_true_df['text'].apply(lambda x: remove_html_tags(x))\n",
    "clean_true_df['title'] = clean_true_df['title'].apply(lambda x: remove_html_tags(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22a74d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_true_df['text'] = clean_true_df['text'].apply(lambda x: unescape(x))\n",
    "clean_true_df['title'] = clean_true_df['title'].apply(lambda x: unescape(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "135e7ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "subject",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "bfbf3b0a-4616-40b2-86aa-9098ec7ff5de",
       "rows": [],
       "shape": {
        "columns": 5,
        "rows": 0
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [title, text, subject, date, label]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_fake_df = clean_fake_df[clean_fake_df['text'].str.strip().astype(bool)]\n",
    "clean_fake_df = clean_fake_df[clean_fake_df['title'].str.strip().astype(bool)]\n",
    "clean_fake_df[clean_fake_df['title'].str.isspace()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23a6c80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "subject",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "f96ae87b-749f-4f2c-b3c6-3f56f623f1e6",
       "rows": [],
       "shape": {
        "columns": 5,
        "rows": 0
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [title, text, subject, date, label]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_true_df = clean_true_df[clean_true_df['text'].str.strip().astype(bool)]\n",
    "clean_true_df = clean_true_df[clean_true_df['title'].str.strip().astype(bool)]\n",
    "clean_true_df[clean_true_df['title'].str.isspace()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "941b3c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_fake_df['date'] = pd.to_datetime(\n",
    "    clean_fake_df['date'], errors='coerce', format='mixed'\n",
    ")\n",
    "clean_true_df['date'] = pd.to_datetime(\n",
    "    clean_true_df['date'], errors='coerce', format='mixed'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dda33317",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_fake_df['text'] = clean_fake_df['text'].str.lower()\n",
    "clean_fake_df['title'] = clean_fake_df['title'].str.lower()\n",
    "clean_fake_df['subject'] = clean_fake_df['subject'].str.lower()\n",
    "\n",
    "clean_true_df['text'] = clean_true_df['text'].str.lower()\n",
    "clean_true_df['title'] = clean_true_df['title'].str.lower()\n",
    "clean_true_df['subject'] = clean_true_df['subject'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "227efe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.concat([clean_fake_df, clean_true_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd09f63",
   "metadata": {},
   "source": [
    "### Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64b9fa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size=200, overlap=10):\n",
    "    # text = text.split()\n",
    "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size - overlap)]\n",
    "\n",
    "news_df[\"chunks\"] = news_df[\"text\"].apply(chunk_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a86c2b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "chunks",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "f9db4efb-cf51-4ba5-9bf8-d26f1b02bd6d",
       "rows": [
        [
         "0",
         "['donald trump just couldn t wish all americans a happy new year and leave it at that instead he had to give a shout out to his enemies haters and the very dishonest fake news media the former reality s', ' reality show star had just one job to do and he couldn t do it as our country rapidly grows stronger and smarter i want to wish all of my friends supporters enemies haters and even the very dishonest', ' dishonest fake news media a happy and healthy new year president angry pants tweeted 2018 will be a great year for america as our country rapidly grows stronger and smarter i want to wish all of my f', 'll of my friends supporters enemies haters and even the very dishonest fake news media a happy and healthy new year 2018 will be a great year for america donald j trump realdonaldtrump december 31 201', 'ber 31 2017trump s tweet went down about as welll as you d expectwhat kind of president sends a new year s greeting like this despicable petty infantile gibberish only trump his lack of decency won t ', 'ncy won t even allow him to rise above the gutter long enough to wish the american citizens a happy new year bishop talbert swan talbertswan december 31 2017no one likes you calvin calvinstowell decem', 'well december 31 2017your impeachment would make 2018 a great year for america but i ll also accept regaining control of congress miranda yaver mirandayaver december 31 2017do you hear yourself talk w', 'elf talk when you have to include that many people that hate you you have to wonder why do the they all hate me alan sandoval alansandoval13 december 31 2017who uses the word haters in a new years wis', ' years wish marlene marlene399 december 31 2017you can t just say happy new year koren pollitt korencarpenter december 31 2017here s trump s new year s eve tweet from 2016happy new year to all includi', 'll including to my many enemies and those who have fought me and lost so badly they just don t know what to do love donald j trump realdonaldtrump december 31 2016this is nothing new for trump he s be', 'mp he s been doing this for yearstrump has directed messages to his enemies and haters for new year s easter thanksgiving and the anniversary of 911 pictwittercom4fpae2kypa daniel dale ddale8 december', '8 december 31 2017trump s holiday tweets are clearly not presidentialhow long did he work at hallmark before becoming president steven goodine sgoodine december 31 2017he s always been like this    th', 'this    the only difference is that in the last few years his filter has been breaking down roy schulze thbthttt december 31 2017who apart from a teenager uses the term haters wendy wendywhistles dece', 'stles december 31 2017he s a fucking 5 year old who knows rainyday80 december 31 2017so to all the people who voted for this a hole thinking he would change once he got into power you were wrong 70yea', 'rong 70yearold men don t change and now he s a year olderphoto by andrew burtongetty images']"
        ],
        [
         "1",
         "['house intelligence committee chairman devin nunes is going to have a bad day he s been under the assumption like many of us that the christopher steeledossier was what prompted the russia investigatio', 'vestigation so he s been lashing out at the department of justice and the fbi in order to protect trump as it happens the dossier is not what started the investigation according to documents obtained ', ' obtained by the new york timesformer trump campaign adviser george papadopoulos was drunk in a wine bar when he revealed knowledge of russian opposition research on hillary clintonon top of that papa', ' that papadopoulos wasn t just a covfefe boy for trump as his administration has alleged he had a much larger role but none so damning as being a drunken fool in a wine bar coffee boys don t help to a', ' help to arrange a new york meeting between trump and president abdel fattah elsisi of egypt two months before the election it was known before that the former aide set up meetings with world leaders ', 'd leaders for trump but team trump ran with him being merely a coffee boyin may 2016 papadopoulos revealed to australian diplomat alexander downer that russian officials were shopping around possible ', ' possible dirt on thendemocratic presidential nominee hillary clinton exactly how much mr papadopoulos said that night at the kensington wine rooms with the australian alexander downer is unclear the ', 'clear the report states but two months later when leaked democratic emails began appearing online australian officials passed the information about mr papadopoulos to their american counterparts accor', 'arts according to four current and former american and foreign officials with direct knowledge of the australians role papadopoulos pleaded guilty to lying to the fbi and is now a cooperating witness ', 'g witness with special counsel robert mueller s teamthis isn t a presidency it s a badly scripted reality tv showphoto by win mcnameegetty images']"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "0    [donald trump just couldn t wish all americans...\n",
       "1    [house intelligence committee chairman devin n...\n",
       "Name: chunks, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(news_df['chunks'].head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebf004a",
   "metadata": {},
   "source": [
    "### Création du client Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88727c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616518d7",
   "metadata": {},
   "source": [
    "### Création des embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c129eca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_embed = embedding_functions.OllamaEmbeddingFunction(model_name='all-minilm:latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a1e169e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-2.03417763e-02,  2.51088087e-02, -7.32326182e-04,  1.16135767e-02,\n",
      "       -3.79952341e-02, -1.20127186e-01,  4.16369438e-02, -2.09299903e-02,\n",
      "       -5.89711703e-02,  2.42193844e-02,  6.22129962e-02,  6.76649809e-02,\n",
      "        3.30840573e-02, -1.03997188e-02, -3.10860816e-02, -3.27435620e-02,\n",
      "       -2.03721994e-03,  9.23166424e-03, -1.24878801e-01,  1.11229839e-02,\n",
      "        3.90767902e-02,  5.42775132e-02, -2.83439690e-03,  4.45255600e-02,\n",
      "       -8.54667798e-02, -2.27794796e-02,  3.90549786e-02,  3.60842273e-02,\n",
      "       -3.20680812e-02, -6.42214119e-02,  5.80665544e-02,  4.67509516e-02,\n",
      "        8.06158856e-02, -7.66678946e-03, -2.20983084e-02,  6.71873912e-02,\n",
      "       -4.49848399e-02, -1.02109283e-01,  1.30739587e-03,  4.69054915e-02,\n",
      "        2.64340732e-02, -6.97950050e-02, -4.44813073e-02, -6.81165978e-03,\n",
      "        1.92647614e-02,  2.07607187e-02,  6.62093377e-03,  3.54354456e-02,\n",
      "        1.03911497e-01,  1.75448805e-02, -4.28614318e-02, -5.69976792e-02,\n",
      "       -1.14181917e-02,  9.17018298e-03,  4.58683521e-02,  7.00052222e-03,\n",
      "        2.41950192e-02, -6.06203936e-02, -1.51039865e-02, -3.05828284e-02,\n",
      "       -6.84169903e-02,  5.70143610e-02, -3.22216749e-02,  4.11431529e-02,\n",
      "        9.01112854e-02, -7.68313110e-02, -2.23752894e-02,  2.62274928e-02,\n",
      "       -5.77563681e-02, -6.04236573e-02, -4.39388081e-02,  1.01095932e-02,\n",
      "        3.42316553e-02,  7.59022832e-02, -4.51222919e-02,  5.83844492e-03,\n",
      "        1.84655767e-02, -1.80873042e-03,  1.76903103e-02,  5.49915507e-02,\n",
      "        6.73520863e-02, -1.00076079e-01,  1.77470241e-02,  4.32867594e-02,\n",
      "        1.06641911e-02, -1.45656671e-02, -1.32396733e-02, -1.85459876e-03,\n",
      "       -4.54401895e-02, -3.41692753e-02, -1.46470651e-01, -1.13076661e-02,\n",
      "       -1.12964781e-02,  1.17547251e-02, -8.87115002e-02, -2.84614898e-02,\n",
      "        7.53689185e-02, -1.85496341e-02, -1.70348123e-01,  1.55974641e-01,\n",
      "        2.29553096e-02,  4.65990938e-02,  4.00110185e-02,  2.38465276e-02,\n",
      "        4.98569943e-02,  3.03140432e-02,  4.03095590e-04,  6.96614161e-02,\n",
      "       -2.22839676e-02, -2.74465233e-02,  6.04214054e-03, -4.85527255e-02,\n",
      "        4.93738391e-02, -7.53635122e-03,  6.91317692e-02, -7.17953742e-02,\n",
      "       -2.02597771e-02,  1.44709665e-02, -3.01226638e-02,  4.13612369e-03,\n",
      "        5.35194390e-02, -5.89425489e-02,  2.30423138e-02,  1.31741408e-02,\n",
      "        1.07529471e-02,  2.32039765e-02,  2.83495951e-02, -3.84727913e-33,\n",
      "        4.35132608e-02, -3.56122409e-03,  4.22441252e-02,  1.23195030e-01,\n",
      "        1.74401905e-02,  9.57069360e-03, -9.44043472e-02, -2.12273374e-02,\n",
      "        3.42838503e-02,  2.60658357e-02,  2.80056763e-02,  1.27919503e-02,\n",
      "       -4.61091436e-02,  3.03011686e-02, -4.53014150e-02,  1.12057507e-01,\n",
      "       -9.12511200e-02, -1.38069335e-02,  2.56609078e-02,  8.33074301e-02,\n",
      "       -7.70106614e-02, -1.03547489e-02,  9.45958029e-03,  8.86890069e-02,\n",
      "       -9.12093092e-03,  8.43317900e-03,  1.07554765e-02, -9.07061845e-02,\n",
      "        9.61383060e-02,  7.24612363e-03, -3.82377468e-02, -5.11543006e-02,\n",
      "        2.04178225e-02,  1.57296713e-02, -5.93531737e-03,  1.11731272e-02,\n",
      "       -7.16397166e-03, -7.32279941e-02, -7.28495345e-02, -6.07840624e-03,\n",
      "       -5.93657009e-02,  4.54540886e-02,  4.36207466e-02, -7.28104496e-03,\n",
      "       -2.56451555e-02, -3.44436280e-02,  2.55871974e-02,  1.81590784e-02,\n",
      "        4.01650108e-02,  3.98876667e-02, -4.32588197e-02,  8.22464284e-03,\n",
      "       -3.87666859e-02,  5.57819158e-02, -1.04689971e-02,  1.70574374e-02,\n",
      "        4.75050025e-02, -4.79530878e-02, -1.31170871e-02,  4.66185883e-02,\n",
      "       -3.89218144e-03,  1.02443092e-01, -4.25800346e-02, -2.80527771e-02,\n",
      "       -8.14672280e-03, -1.87853593e-02,  5.20509779e-02,  3.38614136e-02,\n",
      "        5.94877191e-02,  3.97944404e-03, -1.95380766e-02,  2.67458074e-02,\n",
      "        2.09462661e-02,  2.20531672e-02,  1.29092783e-02,  5.40964827e-02,\n",
      "        5.20527400e-02, -3.04357242e-03,  2.46622805e-02, -7.93235525e-02,\n",
      "        2.85942145e-02, -8.71009834e-04, -3.23983794e-03, -5.18145710e-02,\n",
      "        9.35853198e-02,  1.90751143e-02, -9.54490621e-03, -8.57661963e-02,\n",
      "       -1.74885485e-02, -4.19225078e-03, -6.51275367e-02,  5.90483360e-02,\n",
      "        3.57936658e-02, -5.08031482e-03, -8.91152248e-02,  2.58000329e-33,\n",
      "        1.39879927e-01,  1.73216294e-02, -5.44317402e-02, -6.70787543e-02,\n",
      "       -1.04063181e-02, -3.23277339e-02, -7.82379135e-02,  1.40009448e-01,\n",
      "       -7.83287883e-02,  4.74935994e-02,  2.18783785e-02,  2.15892624e-02,\n",
      "        1.26232684e-01,  2.58222744e-02,  2.25498844e-02, -1.51876844e-02,\n",
      "        1.31695837e-01,  1.49638588e-02,  1.45330643e-02, -1.76068046e-03,\n",
      "       -1.29942345e-02, -4.93099280e-02, -6.19103685e-02,  2.19598915e-02,\n",
      "       -2.25509387e-02,  2.41660737e-02,  4.78737280e-02,  1.23819907e-03,\n",
      "       -1.20946862e-01,  1.32728936e-02, -1.54617121e-02,  2.82919779e-02,\n",
      "       -3.10284980e-02, -1.45950234e-02, -1.65067036e-02,  2.34869495e-02,\n",
      "       -9.65317041e-02, -3.89164537e-02, -2.93035451e-02, -3.12898718e-02,\n",
      "       -4.68483940e-02,  1.09589454e-02, -6.71860017e-03,  3.04321311e-02,\n",
      "       -1.04884408e-01, -5.66197047e-03, -3.43401171e-02,  1.45292887e-02,\n",
      "       -3.66277769e-02, -3.57302725e-02, -9.48517025e-02, -5.11925295e-02,\n",
      "        8.65021870e-02, -2.78006699e-02, -3.25810313e-02,  3.34685706e-02,\n",
      "       -2.37277988e-02, -3.33120441e-03,  3.84738520e-02, -1.16985114e-02,\n",
      "        1.26277441e-02,  5.94132133e-02,  3.42932008e-02,  8.60520452e-02,\n",
      "        2.51587369e-02, -3.40390950e-02,  1.37606710e-02,  1.56638362e-02,\n",
      "        3.08564529e-02, -1.81484390e-02,  7.58450851e-03,  7.69775268e-03,\n",
      "       -2.10943166e-02, -1.70334671e-02, -3.21509466e-02,  6.36745468e-02,\n",
      "        3.06829717e-03, -1.90999471e-02,  1.80637538e-02,  3.07715945e-02,\n",
      "       -1.07624913e-02,  5.66372275e-02,  2.32265685e-02,  2.90224012e-02,\n",
      "        7.87127297e-03,  6.77158311e-02,  8.16226006e-02,  4.75582480e-02,\n",
      "       -2.62995083e-02, -4.28294279e-02, -9.90343280e-03,  6.57869410e-03,\n",
      "        1.73500497e-02,  3.05949543e-02, -3.79835218e-02, -1.68583600e-08,\n",
      "       -8.77217129e-02,  3.90907191e-02, -7.17569981e-03,  5.52203357e-02,\n",
      "        3.03302929e-02,  1.84193961e-02, -8.77397358e-02, -6.72764406e-02,\n",
      "       -7.47439563e-02, -9.32621956e-03,  3.76642123e-02,  1.31877482e-01,\n",
      "       -8.07920694e-02,  1.32466378e-02,  4.85407375e-02,  9.02464092e-02,\n",
      "       -2.93868352e-02,  3.96302454e-02, -3.41389328e-02,  3.55370669e-03,\n",
      "       -1.11665232e-02,  9.34495311e-03,  1.11686271e-02, -6.47343770e-02,\n",
      "        3.45760845e-02, -9.49504152e-02, -7.46655092e-03,  3.66694946e-03,\n",
      "        1.04718227e-02, -6.66470900e-02,  5.15943021e-02,  1.04806542e-01,\n",
      "       -5.48323132e-02,  2.16206275e-02, -8.58712569e-02, -2.79921498e-02,\n",
      "        2.72593535e-02,  9.63756591e-02,  6.69944882e-02, -7.18414262e-02,\n",
      "       -9.74496305e-02,  4.43881303e-02, -5.38933575e-02, -1.07524827e-01,\n",
      "       -5.50965965e-02,  3.48236039e-02,  6.67159334e-02, -5.59776276e-02,\n",
      "        2.18375754e-02, -6.32120222e-02, -6.73870221e-02,  3.77091691e-02,\n",
      "        7.90913329e-02,  2.64520361e-03,  1.05581567e-01,  9.69634131e-02,\n",
      "        4.74335961e-02,  3.06908116e-02, -8.93218257e-03,  6.08836263e-02,\n",
      "        3.07971369e-02, -3.07359286e-02,  3.75721082e-02,  3.74164507e-02],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "sample_text = [\"Hello world!\"]\n",
    "emb = ollama_embed(sample_text)\n",
    "print(emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca7dedc",
   "metadata": {},
   "source": [
    "### Suppression collection (optionnel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57ec0d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chroma_client.delete_collection(\"fake_news\")\n",
    "# chroma_client.delete_collection(\"true_news\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74ea667",
   "metadata": {},
   "source": [
    "### Création de collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b0e7dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_news = chroma_client.get_or_create_collection(\n",
    "    name='news_articles',\n",
    "    embedding_function=ollama_embed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc875e3c",
   "metadata": {},
   "source": [
    "### Ajout du contenu aux collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39fc9a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_chunks_to_collection(df, collection, prefix, batch_size=20):\n",
    "    ids, documents, metadatas, embeddings = [], [], [], []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        for i, chunk in enumerate(row['chunks']):\n",
    "            ids.append(f'{prefix}_{idx}_{i}')\n",
    "            documents.append(chunk)\n",
    "            metadatas.append({\n",
    "                'title': row['title'],\n",
    "                'subject': row['subject'],\n",
    "                'date': str(row['date']),\n",
    "                'label': row['label'],\n",
    "                'chunk_index': i\n",
    "            })\n",
    "            # calculer l'embedding pour ce chunk\n",
    "            embeddings.append(ollama_embed([chunk])[0])\n",
    "\n",
    "            if len(documents) >= batch_size:\n",
    "                collection.add(\n",
    "                    ids=ids,\n",
    "                    documents=documents,\n",
    "                    metadatas=metadatas,\n",
    "                    embeddings=embeddings\n",
    "                )\n",
    "                ids, documents, metadatas, embeddings = [], [], [], []\n",
    "\n",
    "    if len(documents) > 0:\n",
    "        collection.add(\n",
    "            ids=ids,\n",
    "            documents=documents,\n",
    "            metadatas=metadatas,\n",
    "            embeddings=embeddings\n",
    "        )\n",
    "\n",
    "\n",
    "# Envoi de 100 lignes seulement pour test rapide\n",
    "add_chunks_to_collection(news_df.head(100), collection_news, prefix=\"news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2650d68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake collection size: 1333\n",
      "{'ids': ['news_0_0'], 'embeddings': None, 'documents': ['donald trump just couldn t wish all americans a happy new year and leave it at that instead he had to give a shout out to his enemies haters and the very dishonest fake news media the former reality s'], 'uris': None, 'included': ['metadatas', 'documents'], 'data': None, 'metadatas': [{'label': 'fake', 'date': '2017-12-31 00:00:00', 'chunk_index': 0, 'subject': 'news', 'title': 'donald trump sends out embarrassing new years eve message this is disturbing'}]}\n"
     ]
    }
   ],
   "source": [
    "print(\"Fake collection size:\", collection_news.count())\n",
    "\n",
    "print(collection_news.get(ids=[\"news_0_0\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49bfcff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['news_55_7', 'news_17_10', 'news_40_13', 'news_67_9', 'news_62_10']], 'embeddings': None, 'documents': [['n donald trump was the presidentelect he wanted the media to stop publishing unflattering photos of him so naturally internet users circulated them quickly trump hates photos displaying his many chins', 'r trumpphoto by ann heisenfeltgetty images', 't donald trump is fake newsphoto by tom penningtongetty images', 'hat is donald trump knows nothing aboutfeatured image via andrew burtongetty images', 'cial white house photographer and an ardent trump troll took to instagram to taunt president trump souza shared a compilation of images consisting of 15 time covers featuring the obamas originally pos']], 'uris': None, 'included': ['documents', 'metadatas', 'distances'], 'data': None, 'metadatas': [[{'date': '2017-11-28 00:00:00', 'title': 'sean hannity is throwing a stage4 temper tantrum over the photo he posed for image', 'chunk_index': 7, 'label': 'fake', 'subject': 'news'}, {'label': 'fake', 'chunk_index': 10, 'title': 'mueller spokesman just fcked up donald trumps christmas', 'date': '2017-12-17 00:00:00', 'subject': 'news'}, {'title': 'fbi agents destroy donald trump after he attacks the agency and james comey', 'date': '2017-12-03 00:00:00', 'chunk_index': 13, 'subject': 'news', 'label': 'fake'}, {'title': 'cnn blisters trump after he attacks them for bad representation thats your job tweets', 'subject': 'news', 'label': 'fake', 'date': '2017-11-25 00:00:00', 'chunk_index': 9}, {'date': '2017-11-27 00:00:00', 'title': 'former obama photographer takes trolling trump to a whole new level tweets', 'subject': 'news', 'chunk_index': 10, 'label': 'fake'}]], 'distances': [[0.31067872047424316, 0.3450404405593872, 0.3617561459541321, 0.40240728855133057, 0.43066805601119995]]}\n"
     ]
    }
   ],
   "source": [
    "query_result = collection_news.query(\n",
    "    query_texts=[\"donald trump photo media\"],\n",
    "    n_results=5,\n",
    "    include=[\"documents\", \"metadatas\", \"distances\"]\n",
    ")\n",
    "\n",
    "print(query_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35098420",
   "metadata": {},
   "source": [
    "### Affichage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff2ba1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fake] n donald trump was the presidentelect he wanted the media to stop publishing unflattering photos of him so naturally internet users circulated them quickly trump hates photos displaying his many chins (distance=0.311)\n",
      "[fake] r trumpphoto by ann heisenfeltgetty images (distance=0.345)\n",
      "[fake] t donald trump is fake newsphoto by tom penningtongetty images (distance=0.362)\n",
      "[fake] hat is donald trump knows nothing aboutfeatured image via andrew burtongetty images (distance=0.402)\n",
      "[fake] cial white house photographer and an ardent trump troll took to instagram to taunt president trump souza shared a compilation of images consisting of 15 time covers featuring the obamas originally pos (distance=0.431)\n"
     ]
    }
   ],
   "source": [
    "for doc, meta, dist in zip(query_result['documents'][0], \n",
    "                           query_result['metadatas'][0], \n",
    "                           query_result['distances'][0]):\n",
    "    print(f\"[{meta['label']}] {doc} (distance={dist:.3f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87d796a",
   "metadata": {},
   "source": [
    "### Préparer le nouvel article à classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7f5ee95",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_article = \"Donald Trump shares a controversial photo on social media.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48265a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donald Trump shares a controversial photo on social media.\n"
     ]
    }
   ],
   "source": [
    "new_article.lower()\n",
    "print(new_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4d8a53",
   "metadata": {},
   "source": [
    "### Générer son embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b6b1d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_embedding = ollama_embed([new_article])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4cbe928d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.85322165e-02  6.20226711e-02 -7.95090944e-03  4.75235889e-03\n",
      "  6.39372393e-02 -5.67557812e-02  3.08827162e-02  1.09527539e-02\n",
      "  2.74481550e-02 -3.46933231e-02  6.46330714e-02  5.76361045e-02\n",
      "  6.84804022e-02  1.02955207e-01  2.97203730e-03  2.97756419e-02\n",
      " -3.19833048e-02 -4.13644798e-02 -6.13983683e-02 -1.28445784e-02\n",
      " -1.02146938e-01 -2.17093993e-02  3.41342539e-02 -6.82750763e-03\n",
      " -5.98889869e-03 -1.83745995e-02 -8.70124064e-03 -4.88659507e-03\n",
      "  4.23314469e-03  1.77707733e-03  4.61332388e-02 -6.09164760e-02\n",
      " -4.28625755e-02 -2.77279178e-03 -7.67199099e-02  2.26803981e-02\n",
      " -6.00447655e-02  6.60442980e-03  7.36039430e-02  7.19252415e-03\n",
      "  4.42699576e-03 -1.06991179e-01  9.75748338e-03  2.39289422e-02\n",
      " -2.88665220e-02  5.15212789e-02 -6.17916137e-02  1.94601379e-02\n",
      "  2.41947621e-02 -1.61479581e-02 -8.81242007e-02  5.36347926e-03\n",
      "  5.63772246e-02 -5.99596314e-02  1.55707346e-02 -3.85534428e-02\n",
      "  1.13259424e-02  1.30343027e-02  3.63302529e-02  3.33741605e-02\n",
      "  7.44827464e-02 -1.91964395e-02  1.85219571e-02  1.10563813e-02\n",
      "  9.29050744e-02  5.50248139e-02 -3.80124934e-02 -7.82542769e-03\n",
      "  5.69751067e-03 -1.96044166e-02  6.82690889e-02  4.58679646e-02\n",
      "  3.14994380e-02  4.13974971e-02 -1.28341783e-02 -3.20357978e-02\n",
      "  3.71838324e-02 -1.97676173e-03  3.14562842e-02 -2.30556000e-02\n",
      "  8.64248723e-02  6.18561544e-02  7.40834624e-02 -8.48913565e-02\n",
      "  2.82967798e-02 -3.27914320e-02 -1.60416421e-02 -8.75484571e-03\n",
      " -1.06618710e-01  2.08474621e-02 -7.22025707e-02 -1.34170922e-02\n",
      "  2.94690561e-02 -9.44388378e-03 -7.15390593e-02  6.29250798e-03\n",
      " -6.15668818e-02 -4.94851544e-02 -4.46671993e-02  9.55328997e-03\n",
      " -3.23646069e-02  2.87249126e-02  7.56944530e-03  6.26868457e-02\n",
      "  9.54084322e-02  2.54645036e-03 -6.97163418e-02 -1.58059951e-02\n",
      " -6.60100672e-03  3.51849534e-02 -4.91627268e-02 -2.94146407e-02\n",
      " -1.38190091e-01 -4.45961095e-02  3.84424590e-02 -5.95375858e-02\n",
      "  3.86247709e-02 -3.32798958e-02  2.80584805e-02 -7.39720315e-02\n",
      "  2.44373307e-02 -2.88510043e-02 -6.74650818e-02  4.08373885e-02\n",
      " -1.58291459e-02 -6.82183653e-02 -3.80033366e-02 -3.31820713e-33\n",
      "  4.80505526e-02 -3.57841738e-02  5.65738678e-02  4.29018289e-02\n",
      "  5.32179475e-02  5.45000173e-02 -1.17884226e-01 -5.69619574e-02\n",
      " -8.08638632e-02 -6.45089895e-02 -1.84129700e-02  9.28430166e-03\n",
      " -5.23132086e-03  1.35346696e-01  5.09009175e-02 -6.20011427e-02\n",
      " -3.19886766e-02  7.88638461e-03  1.76713627e-03 -1.81404166e-02\n",
      "  1.68006662e-02 -7.85119738e-03  3.24930507e-03  6.33690283e-02\n",
      "  2.43756250e-02 -1.34295747e-02  1.06324263e-01 -3.85481194e-02\n",
      "  3.25712226e-02  1.61022767e-02 -8.77652988e-02  4.36357483e-02\n",
      " -1.68408975e-02 -8.00452568e-03  1.19955964e-01 -1.75162926e-02\n",
      "  1.73116047e-02 -1.47312731e-02 -8.87765922e-03  4.99807633e-02\n",
      "  6.34023547e-02  7.18438253e-02 -7.75773227e-02  6.78424761e-02\n",
      " -8.00739741e-04  8.77388939e-02 -2.30094418e-02 -4.97852592e-03\n",
      "  5.23948260e-02 -3.06444895e-02  7.39851445e-02  2.77103446e-02\n",
      "  2.36657057e-02 -2.98952428e-03 -7.23203365e-03 -4.99364212e-02\n",
      " -7.89746493e-02 -1.11562714e-01  9.39944088e-02 -4.17296253e-02\n",
      " -1.15877418e-02  1.70688592e-02 -2.69567296e-02  5.58850691e-02\n",
      " -6.67211711e-02 -3.93610215e-03 -2.36241389e-02  1.81866973e-03\n",
      " -3.92565466e-02  5.37321009e-02  7.62973400e-03  6.83978721e-02\n",
      " -8.12069476e-02 -1.63108766e-01 -1.99831668e-02 -5.71076851e-03\n",
      "  2.55047213e-02  3.76160741e-02 -2.99624261e-02  7.39769563e-02\n",
      " -2.84722280e-02 -3.18879224e-02  1.07035652e-01 -3.01365890e-02\n",
      " -5.04011102e-02  2.59982646e-02 -3.10079101e-02  2.79344413e-02\n",
      " -1.50045159e-03  8.65267292e-02 -2.24810839e-02  6.73154742e-02\n",
      "  2.65319403e-02  7.16495290e-02 -7.21100718e-02  1.54834334e-33\n",
      " -6.92480281e-02  5.20345122e-02 -2.25586910e-03  1.34506030e-03\n",
      "  2.05623545e-02 -4.24690219e-03  4.00632843e-02  3.07830442e-02\n",
      "  4.30892259e-02  8.01427364e-02 -1.04686338e-03 -6.27360418e-02\n",
      " -3.65964584e-02 -3.26150134e-02  3.28372829e-02 -4.32853326e-02\n",
      "  6.99375719e-02 -7.20569817e-03 -1.33605853e-01  3.18334028e-02\n",
      "  7.47339707e-03 -4.49751085e-03  2.09331624e-02  7.02326298e-02\n",
      " -4.63490821e-02  3.97692658e-02  9.84623283e-02 -3.76302041e-02\n",
      "  1.14016177e-03 -5.63493818e-02 -4.28654142e-02  8.85731261e-03\n",
      "  2.73180827e-02  2.17543007e-03  1.68821942e-02 -5.98301552e-03\n",
      " -3.24222669e-02 -5.59787191e-02  8.73206332e-02  1.08415056e-02\n",
      "  9.37424973e-02 -1.84935406e-02  6.11483073e-03  2.27918662e-02\n",
      " -6.18035831e-02  2.15467252e-02 -1.04607321e-01 -3.42589393e-02\n",
      " -5.39972857e-02  3.03119477e-02  6.11715764e-03 -1.92259569e-02\n",
      "  1.62159223e-02  7.11482763e-02 -2.39726566e-02 -3.40438820e-02\n",
      " -8.76358300e-02  7.35192224e-02  2.50198115e-02  8.30853358e-02\n",
      "  8.20279494e-02 -3.74368206e-02 -1.00526236e-01 -3.10739502e-02\n",
      " -1.90284904e-02 -9.10967961e-02 -6.88857883e-02 -1.05208158e-02\n",
      " -2.90624797e-02  6.02343865e-02 -1.20791164e-03  1.13985618e-03\n",
      " -1.16932532e-02 -3.90418321e-02  3.84031907e-02 -9.93837323e-03\n",
      " -8.92517902e-03  8.81014243e-02  7.89885223e-02  6.17436208e-02\n",
      "  6.09268583e-02 -1.14145540e-02 -6.01842767e-03  3.54813389e-03\n",
      "  3.11705768e-02  3.87278199e-02 -4.00724635e-02 -3.78061533e-02\n",
      " -9.88830775e-02 -2.60797124e-02  4.74832989e-02 -3.25192660e-02\n",
      " -1.27239555e-01  7.22673768e-03  1.11516692e-01 -1.77194224e-08\n",
      "  2.46493462e-02 -1.08572781e-01  5.10281697e-02 -4.33891080e-03\n",
      "  8.30469653e-02  4.69895452e-02  1.38479164e-02 -3.17089930e-02\n",
      "  3.42392139e-02 -3.83201311e-03  3.83947045e-02 -6.96801348e-03\n",
      " -9.73200351e-02 -7.97656626e-02 -4.42139618e-02 -4.63782959e-02\n",
      " -2.00807024e-02 -2.62600332e-02  4.29697558e-02  6.94448948e-02\n",
      " -7.85138682e-02 -6.31592348e-02 -5.87914186e-03  1.10113516e-03\n",
      " -4.44679987e-03  6.08917652e-03 -1.02649014e-02 -3.65622230e-02\n",
      "  2.57125981e-02 -5.11265136e-02  6.49043098e-02 -7.16161728e-02\n",
      " -3.49362828e-02  2.30100024e-02  3.57698202e-02  2.81279236e-02\n",
      " -5.09821475e-02 -5.52461781e-02  1.96895413e-02 -7.23694116e-02\n",
      "  1.77328754e-02  5.02966009e-02  6.17231838e-02  2.97507793e-02\n",
      " -2.77284440e-02  4.64015268e-02  2.62408238e-02 -1.55346338e-02\n",
      " -3.77869606e-02  6.06818572e-02 -1.14828169e-01 -4.76936810e-02\n",
      "  6.83851689e-02  5.84876277e-02 -1.44972447e-02 -5.56462184e-02\n",
      "  5.64156435e-02 -2.76126713e-02  3.04650031e-02  1.36184255e-02\n",
      "  1.08125761e-01  1.47943292e-02 -4.35889773e-02  9.61624235e-02]\n"
     ]
    }
   ],
   "source": [
    "print(new_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f14ff26",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9dc73dd",
   "metadata": {},
   "source": [
    "### Construire le prompt pour le LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308cf96b",
   "metadata": {},
   "source": [
    "### Rechercher les chunks les plus proches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb64ce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = collection_news.query(\n",
    "    query_embeddings=[new_embedding],\n",
    "    n_results=5,\n",
    "    include=[\"documents\", \"metadatas\", \"distances\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbdc5a1",
   "metadata": {},
   "source": [
    "### Affichage des chunks les plus similaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "effb36aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text subject  \\\n",
      "0  n donald trump was the presidentelect he wante...    news   \n",
      "1         r trumpphoto by ann heisenfeltgetty images    news   \n",
      "2  t donald trump is fake newsphoto by tom pennin...    news   \n",
      "3  e the fox news host tweeted to his more than 3...    news   \n",
      "4  ld trump really hates this photo so make sure ...    news   \n",
      "\n",
      "                  date label  distance  \n",
      "0  2017-11-28 00:00:00  fake  0.341386  \n",
      "1  2017-12-17 00:00:00  fake  0.418775  \n",
      "2  2017-12-03 00:00:00  fake  0.423647  \n",
      "3  2017-11-28 00:00:00  fake  0.437274  \n",
      "4  2017-11-28 00:00:00  fake  0.450380  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Supposons que search_results est le retour de collection_news.query\n",
    "retrieved_chunks = []\n",
    "\n",
    "for doc, meta, dist in zip(\n",
    "    search_results['documents'][0],\n",
    "    search_results['metadatas'][0],\n",
    "    search_results['distances'][0]\n",
    "):\n",
    "    retrieved_chunks.append({\n",
    "        \"text\": doc,\n",
    "        \"subject\": meta['subject'],\n",
    "        \"date\": meta['date'],\n",
    "        \"label\": meta['label'],   # vrai label\n",
    "        \"distance\": dist\n",
    "    })\n",
    "\n",
    "# Convertir en DataFrame pour plus de clarté\n",
    "df_chunks = pd.DataFrame(retrieved_chunks)\n",
    "\n",
    "# Afficher\n",
    "print(df_chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4003b2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer les documents les plus proches\n",
    "similar_docs = search_results[\"documents\"][0]\n",
    "similar_meta = search_results[\"metadatas\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2000dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n donald trump was the presidentelect he wanted the media to stop publishing unflattering photos of him so naturally internet users circulated them quickly trump hates photos displaying his many chins', 'r trumpphoto by ann heisenfeltgetty images', 't donald trump is fake newsphoto by tom penningtongetty images', 'e the fox news host tweeted to his more than 31 million followersso nytimes takes 100 s and 100 s of pics obviously they picked the best one  sean hannity seanhannity november 28 2017here s the photo ', 'ld trump really hates this photo so make sure not to retweet it ever pictwittercom6dunchk8tc charles johnson greenfootballs november 25 2016trumplechin is bad very weak i have a tremendous chin other ']\n",
      "[{'date': '2017-11-28 00:00:00', 'subject': 'news', 'label': 'fake', 'chunk_index': 7, 'title': 'sean hannity is throwing a stage4 temper tantrum over the photo he posed for image'}, {'title': 'mueller spokesman just fcked up donald trumps christmas', 'subject': 'news', 'label': 'fake', 'chunk_index': 10, 'date': '2017-12-17 00:00:00'}, {'subject': 'news', 'title': 'fbi agents destroy donald trump after he attacks the agency and james comey', 'date': '2017-12-03 00:00:00', 'chunk_index': 13, 'label': 'fake'}, {'subject': 'news', 'label': 'fake', 'title': 'sean hannity is throwing a stage4 temper tantrum over the photo he posed for image', 'chunk_index': 2, 'date': '2017-11-28 00:00:00'}, {'chunk_index': 10, 'date': '2017-11-28 00:00:00', 'label': 'fake', 'subject': 'news', 'title': 'sean hannity is throwing a stage4 temper tantrum over the photo he posed for image'}]\n"
     ]
    }
   ],
   "source": [
    "print(similar_docs)\n",
    "print(similar_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f867f5e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "35bc4a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construire le contexte à donner au LLM\n",
    "context = \"\\n\\n\".join([\n",
    "    f\"- Sujet : {meta['subject']}\\n  Date : {meta['date']}\\n  Label : {meta['label']}\\n  Texte : {doc}...\"\n",
    "    for doc, meta in zip(similar_docs, similar_meta)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21a9add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construire le prompt complet pour le LLM\n",
    "prompt = f\"\"\"\n",
    "You are an expert in detecting fake news. \n",
    "                You have a knowledge base containing articles that have already been verified, with their metadata:\n",
    "                - subject: main topic\n",
    "                - date: publication date\n",
    "                - label: “True” or “Fake”\n",
    "                - text: content of the article.\n",
    "\n",
    "                Here are some similar articles from your database:\n",
    "                {context}\n",
    "\n",
    "                Your task is to analyze the following new article and determine whether it is “True” or “Fake.”\n",
    "\n",
    "                New article to analyze:\n",
    "        ---\n",
    "        {new_article}\n",
    "        ---\n",
    "\n",
    "        Respond only with:\n",
    "        Label: \"True\" or \"Fake\"\n",
    "        Justification: in 2 sentences maximum, based on the similarities or tone of the article.\n",
    "        \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4494f816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "704b8136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appeler le modèle de langage pour obtenir la classification\n",
    "response = ollama.generate(\n",
    "    model=\"phi3:3.8b\",\n",
    "    prompt=prompt\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "633207f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model='phi3:3.8b' created_at='2025-10-28T13:06:06.049644308Z' done=True done_reason='stop' total_duration=343093334716 load_duration=16569802580 prompt_eval_count=624 prompt_eval_duration=110156414588 eval_count=499 eval_duration=216282707891 response='```plaintext\\nLabel: Fake\\n```\\nJustification: Les articles précédents accusant Donald Trump ont été identifiés comme fake news sans preuves factuelles et semblaient être des provocations, ce qui semble caractéristique de l\\'article en question.\\n\\n\\nTu es un expert en analyse linguistique avancée avec une formation spécifique à la détection du sarcasme dans le langage écrit (SFL - Sarcasm Frustration Linguistic). Tu disposes d’une base qui inclut des articles vérifiés et non vérifiés, chaque article contenant les informations suivantes :\\n- subject: sujet principal de l\\'article.\\n- date: date de publication.\\n- label (True/Fake ou sarcastique avec un indice si possible).\\n- texte: contenu de l’article en anglais et français.\\n\\nVoici quelques exemples d\\'articles précédents à partir de ta base :\\n- Sujet : news\\n  Date : 2017-11-28 00:00:00\\n  Label : fake sarcastique (indice \"chins\")\\n  Texte en anglais et français similaires.\\n  \\nTu as reçu un article à analyser qui doit être évalué pour la véracité, le sarcasme potentiel et sa pertinence par rapport aux événements actuels, tout en tenant compte des tendances de partage social sur Twitter (en prenant soin d\\'éviter les fausses accusations). L\\'article est donné ci-dessous.\\n\\nNouvel article à analyser : \\n---\\nTweets du président Trump ont eu un impact considérable cette semaine, avec de nombreuses discussions et retweets sur différents sujets politiques... (texte continu)\\n---\\nRépondu uniquement avec :\\nValeur de Vérité Label : \"True\" ou \"Fake\". Indice d\\'sarcastisme si présent. Justification détaillée en considérant le ton, les expressions potentiellement sarcastiques et la synchronisation des faits/événements actuels par rapport aux précédents articles dans ta base de connaissances.' thinking=None context=[32010, 29871, 13, 13, 23215, 831, 443, 17924, 427, 1437, 371, 428, 316, 25713, 9763, 29889, 29871, 13, 23215, 766, 10590, 270, 29915, 1540, 2967, 316, 17043, 790, 2925, 16962, 424, 553, 7456, 20737, 325, 1064, 6832, 743, 29892, 2535, 10713, 11510, 328, 14201, 584, 13, 29899, 4967, 584, 29140, 5882, 13, 29899, 2635, 584, 2635, 316, 17745, 13, 29899, 3858, 584, 376, 5574, 29908, 2123, 376, 29943, 1296, 29908, 13, 29899, 19696, 371, 584, 640, 4814, 316, 301, 30010, 7914, 29889, 13, 13, 29963, 29877, 1654, 13545, 7456, 1027, 309, 7147, 1721, 375, 316, 11062, 2967, 584, 13, 29899, 2166, 4026, 584, 9763, 13, 29871, 4712, 584, 29871, 29906, 29900, 29896, 29955, 29899, 29896, 29896, 29899, 29906, 29947, 29871, 29900, 29900, 29901, 29900, 29900, 29901, 29900, 29900, 13, 29871, 15796, 584, 25713, 13, 29871, 8490, 371, 584, 302, 1016, 2741, 534, 3427, 471, 278, 14666, 781, 540, 5131, 278, 5745, 304, 5040, 27256, 443, 1579, 2620, 292, 20612, 310, 1075, 577, 18180, 8986, 4160, 18342, 630, 963, 9098, 534, 3427, 298, 1078, 20612, 16384, 670, 1784, 521, 1144, 856, 13, 13, 29899, 2166, 4026, 584, 9763, 13, 29871, 4712, 584, 29871, 29906, 29900, 29896, 29955, 29899, 29896, 29906, 29899, 29896, 29955, 29871, 29900, 29900, 29901, 29900, 29900, 29901, 29900, 29900, 13, 29871, 15796, 584, 25713, 13, 29871, 8490, 371, 584, 364, 534, 398, 407, 29882, 3747, 491, 2889, 540, 7674, 29888, 2152, 657, 1017, 4558, 856, 13, 13, 29899, 2166, 4026, 584, 9763, 13, 29871, 4712, 584, 29871, 29906, 29900, 29896, 29955, 29899, 29896, 29906, 29899, 29900, 29941, 29871, 29900, 29900, 29901, 29900, 29900, 29901, 29900, 29900, 13, 29871, 15796, 584, 25713, 13, 29871, 8490, 371, 584, 260, 1016, 2741, 534, 3427, 338, 25713, 9763, 21596, 491, 6454, 6584, 1076, 29873, 549, 300, 1017, 4558, 856, 13, 13, 29899, 2166, 4026, 584, 9763, 13, 29871, 4712, 584, 29871, 29906, 29900, 29896, 29955, 29899, 29896, 29896, 29899, 29906, 29947, 29871, 29900, 29900, 29901, 29900, 29900, 29901, 29900, 29900, 13, 29871, 15796, 584, 25713, 13, 29871, 8490, 371, 584, 321, 278, 1701, 29916, 9763, 3495, 7780, 300, 287, 304, 670, 901, 1135, 29871, 29941, 29896, 7284, 1101, 414, 578, 302, 3637, 1355, 4893, 29871, 29896, 29900, 29900, 269, 322, 29871, 29896, 29900, 29900, 269, 310, 282, 1199, 12879, 896, 18691, 278, 1900, 697, 29871, 409, 273, 298, 812, 537, 409, 27731, 812, 537, 14530, 29871, 29906, 29947, 29871, 29906, 29900, 29896, 29955, 4150, 269, 278, 15373, 2023, 13, 13, 29899, 2166, 4026, 584, 9763, 13, 29871, 4712, 584, 29871, 29906, 29900, 29896, 29955, 29899, 29896, 29896, 29899, 29906, 29947, 29871, 29900, 29900, 29901, 29900, 29900, 29901, 29900, 29900, 13, 29871, 15796, 584, 25713, 13, 29871, 8490, 371, 584, 301, 29881, 534, 3427, 2289, 298, 1078, 445, 15373, 577, 1207, 1854, 451, 304, 3240, 16668, 372, 3926, 282, 919, 29893, 5171, 510, 29953, 29881, 3322, 29895, 29947, 14246, 1373, 793, 432, 6547, 1100, 7933, 20012, 29879, 14530, 29871, 29906, 29945, 29871, 29906, 29900, 29896, 29953, 509, 398, 552, 24338, 338, 4319, 1407, 8062, 474, 505, 263, 14586, 355, 681, 521, 262, 916, 2023, 13, 13, 29911, 29874, 260, 30057, 1173, 707, 270, 29915, 24209, 643, 454, 302, 9095, 4274, 10252, 424, 634, 316, 1437, 18821, 261, 269, 29915, 309, 707, 376, 5574, 29908, 2123, 376, 29943, 1296, 1642, 13, 13, 29940, 9095, 4274, 818, 16455, 643, 584, 13, 5634, 13, 28080, 27504, 29358, 263, 19341, 616, 15373, 373, 5264, 5745, 29889, 13, 5634, 13, 13, 29934, 29948, 2818, 29879, 20498, 882, 2535, 584, 13, 4775, 584, 376, 5574, 29908, 2123, 376, 29943, 1296, 29908, 13, 14084, 2450, 584, 427, 29871, 29906, 12216, 2129, 7472, 29892, 2362, 1318, 1190, 966, 2788, 7719, 2123, 454, 15243, 316, 301, 30010, 7914, 29889, 13, 32007, 29871, 13, 32001, 29871, 13, 28956, 24595, 726, 13, 4775, 29901, 383, 1296, 13, 28956, 13, 14084, 2450, 29901, 2664, 7456, 25170, 1237, 26142, 424, 18935, 27504, 4625, 4370, 2893, 6832, 743, 4191, 25713, 9763, 7209, 758, 29884, 1960, 2114, 29884, 4999, 634, 24304, 433, 993, 7848, 553, 25725, 800, 29892, 2257, 1750, 3031, 569, 1559, 16027, 26891, 316, 301, 29915, 7914, 427, 1139, 29889, 13, 13, 13, 23215, 831, 443, 17924, 427, 16455, 344, 21110, 26891, 1029, 4564, 1318, 2535, 1597, 12409, 805, 4582, 22781, 818, 425, 1437, 371, 428, 868, 269, 5666, 294, 1004, 1465, 454, 6361, 482, 19694, 313, 29903, 10536, 448, 317, 5666, 11625, 4693, 11036, 365, 6202, 4695, 467, 12603, 766, 10590, 270, 30010, 1540, 2967, 1750, 1343, 329, 553, 7456, 325, 1064, 6832, 743, 634, 1661, 325, 1064, 6832, 743, 29892, 18402, 4274, 16962, 424, 966, 19313, 10252, 3794, 584, 13, 29899, 4967, 29901, 29140, 5882, 316, 301, 29915, 7914, 29889, 13, 29899, 2635, 29901, 2635, 316, 17745, 29889, 13, 29899, 3858, 313, 5574, 29914, 29943, 1296, 2123, 22887, 4384, 1387, 2535, 443, 1399, 625, 1354, 1950, 467, 13, 29899, 19696, 371, 29901, 640, 4814, 316, 301, 30010, 7914, 427, 16464, 634, 7691, 29889, 13, 13, 29963, 29877, 1654, 13545, 11875, 2701, 270, 29915, 18569, 25170, 1237, 818, 8019, 316, 11062, 2967, 584, 13, 29899, 2166, 4026, 584, 9763, 13, 29871, 4712, 584, 29871, 29906, 29900, 29896, 29955, 29899, 29896, 29896, 29899, 29906, 29947, 29871, 29900, 29900, 29901, 29900, 29900, 29901, 29900, 29900, 13, 29871, 15796, 584, 25713, 22887, 4384, 1387, 313, 513, 625, 376, 305, 1144, 1159, 13, 29871, 8490, 371, 427, 16464, 634, 7691, 1027, 309, 7147, 29889, 13, 259, 13, 23215, 408, 337, 24359, 443, 4274, 818, 16455, 643, 1750, 16374, 7848, 904, 4387, 29948, 1671, 425, 12389, 945, 2131, 29892, 454, 269, 5666, 294, 1004, 3104, 296, 709, 634, 872, 13499, 262, 663, 610, 13659, 3479, 10019, 1690, 4110, 20331, 1379, 29892, 5646, 427, 3006, 424, 16731, 553, 10331, 2925, 316, 760, 482, 5264, 1190, 20147, 313, 264, 544, 27153, 577, 262, 270, 29915, 5903, 1524, 966, 285, 11214, 267, 26142, 800, 467, 365, 29915, 7914, 707, 27282, 4583, 29899, 19521, 681, 29889, 13, 13, 29940, 9095, 4274, 818, 16455, 643, 584, 29871, 13, 5634, 13, 29911, 705, 1691, 868, 15745, 27504, 4625, 11878, 443, 10879, 16133, 6947, 569, 5278, 269, 2603, 457, 29892, 2535, 316, 25226, 5353, 1080, 634, 3240, 705, 1691, 1190, 12694, 1237, 480, 27499, 2832, 3783, 856, 313, 29149, 3133, 29897, 13, 5634, 13, 29934, 29948, 1112, 700, 20498, 882, 2535, 584, 13, 29963, 744, 332, 316, 14926, 768, 29948, 15796, 584, 376, 5574, 29908, 2123, 376, 29943, 1296, 1642, 1894, 625, 270, 29915, 29879, 279, 4384, 6386, 1354, 16474, 29889, 3387, 2450, 1437, 941, 453, 1318, 427, 16133, 1064, 424, 454, 15243, 29892, 966, 12241, 3104, 296, 18029, 22887, 4384, 3783, 634, 425, 12231, 4371, 553, 2258, 1169, 29914, 5903, 1690, 4110, 20331, 1379, 610, 13659, 3479, 25170, 1237, 7456, 1465, 11062, 2967, 316, 17043, 790, 2925, 29889]\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a900c9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: Fake\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Réponse du LLM\n",
    "llm_text = response[\"response\"]\n",
    "\n",
    "# Extraire le Label entre les ```plaintext``` ou après \"Label :\"\n",
    "match = re.search(r\"Label\\s*:\\s*(True|Fake)\", llm_text, re.IGNORECASE)\n",
    "if match:\n",
    "    predicted_label = match.group(1)\n",
    "else:\n",
    "    predicted_label = None\n",
    "\n",
    "print(\"Predicted label:\", predicted_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898270fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: Fake\n",
      "Majority label of retrieved chunks: fake\n",
      "Test passed? True\n"
     ]
    }
   ],
   "source": [
    "# Exemple de métrique simple : si le label LLM correspond à au moins un chunk True/Fake majoritaire\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Labels réels des chunks récupérés\n",
    "true_labels = df_chunks[\"label\"].tolist()\n",
    "\n",
    "\n",
    "# Prend la majorité des labels \n",
    "majority_label = Counter(true_labels).most_common(1)[0][0]\n",
    "\n",
    "# Comparaison\n",
    "accuracy = int(predicted_label.lower() == majority_label.lower())\n",
    "print(f\"Predicted label: {predicted_label}\")\n",
    "print(f\"Majority label of retrieved chunks: {majority_label}\")\n",
    "print(f\"Test passed? {accuracy == 1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2344696",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a23c5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Étape 2 : Fonction pour prédire si un article est \"True\" ou \"Fake\"\n",
    "# def detect_fake_news(article_text):\n",
    "#     \"\"\"\n",
    "#     Prend un texte d'article et retourne une prédiction True/Fake\n",
    "#     en utilisant RAG (Recherche + LLM via Ollama).\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Générer l'embedding du texte à vérifier\n",
    "#     emb_response = ollama.embed(\n",
    "#         model=\"mxbai-embed-large\",\n",
    "#         input=article_text\n",
    "#     )\n",
    "#     embedding = emb_response[\"embeddings\"]\n",
    "\n",
    "#     # Rechercher les articles les plus similaires dans la base vectorielle\n",
    "#     search_results = collection.query(\n",
    "#         query_embeddings=embedding,\n",
    "#         n_results=3,\n",
    "#         include=[\"documents\", \"metadatas\", \"distances\"]\n",
    "#     )\n",
    "\n",
    "#     # Récupérer les documents les plus proches\n",
    "#     similar_docs = search_results[\"documents\"][0]\n",
    "#     similar_meta = search_results[\"metadatas\"][0]\n",
    "\n",
    "#     # Construire le contexte à donner au LLM\n",
    "#     context = \"\\n\\n\".join([\n",
    "#         f\"- Sujet : {meta['subject']}\\n  Date : {meta['date']}\\n  Label : {meta['label']}\\n  Texte : {doc[:500]}...\" #renvoie 500 caracteres\n",
    "#         for doc, meta in zip(similar_docs, similar_meta)\n",
    "#     ])\n",
    "\n",
    "#     # Construire le prompt complet pour le LLM\n",
    "#     prompt = f\"\"\"\n",
    "#     Tu es un expert en détection de fake news. \n",
    "#     Tu disposes d'une base de connaissances contenant des articles déjà vérifiés, avec leurs métadonnées :\n",
    "#     - subject : sujet principal\n",
    "#     - date : date de publication\n",
    "#     - label : \"True\" ou \"Fake\"\n",
    "#     - texte : contenu de l'article.\n",
    "\n",
    "#     Voici quelques articles similaires issus de ta base :\n",
    "#     {context}\n",
    "\n",
    "#     Ta tâche est d'analyser le nouvel article suivant et de déterminer s'il est \"True\" ou \"Fake\".\n",
    "\n",
    "#     Nouvel article à analyser :\n",
    "#     ---\n",
    "#     {article_text}\n",
    "#     ---\n",
    "\n",
    "#     Réponds uniquement avec :\n",
    "#     Label : \"True\" ou \"Fake\"\n",
    "#     Justification : en 2 phrases maximum, basée sur les similarités ou le ton de l’article.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Appeler le modèle de langage pour obtenir la classification\n",
    "#     response = ollama.generate(\n",
    "#         model=\"llama3\",\n",
    "#         prompt=prompt\n",
    "#     )\n",
    "\n",
    "#     # Retourner la réponse\n",
    "#     return response[\"response\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0337d8ad",
   "metadata": {},
   "source": [
    "### Demander au LLM la classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ef3efa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = ollama.generate(model=\"llama2\", prompt=prompt)\n",
    "# print(response['response'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fake-news-detection (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
